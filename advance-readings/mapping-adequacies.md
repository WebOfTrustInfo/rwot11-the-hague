# Mapping adequacies: explicit guidance for pragmatists, corner cutters, and the impatient

by Juan Caballero \( [email](mailto:caballerojuan_AT_pm.me) \)

The RWoT community skews towards CTOs, perfectionists, over-engineerers, and people with decades of experience building production-grade software.  But as standards largely incubated here go mainstream, a whole range of people all over the world are going to start cloning repos and hacking together things willy-nilly.  My proposal for this particular juncture in the history of the now-live specs would be to take a step back and do a pass of highly **pessimistic**, skeptical, bad-faith editing towards past and current documentation: How badly could this get f*&^d up in the hands of a bunch of script kitties?  
I personally *do not* think shaming people for cutting corners is going to help adoption or decentralization-- but we can promote thinking in tiers and relative terms rather than absolute ones about *contextual* sovereignty or *degrees* of privacy-preservations. Making a case for building some things the slow/hard way so as to minimize the chances of needing to be rebuilt/refactored later is best done in an even-handed, understanding, nonjudgmental way.

Maybe this could take the form of "explain it to me like I'm in kindergarten" tutorials and appendices full of sternly-worded warnings being added to whitepapers.  Maybe the best approach has nothing to do with whitepapers anyways: maybe some adequacy/compatibility matrices should be published so that planners, funders, and non-technical folks can grok as quickly as possible the trade-offs in building something ASAP for the exigencies of today. One way of interpreting this topic paper would be to form a panel at RWoT that produces such tutorials and/or a guidance document for non-technical executive and/or governmental readers.  Another way of acting on it would be not to form **one** panel at RWoT, but instead to set aside a block of time in the schedule (maybe on day two or three?) for **each working group** to consider and cross-discuss these questions, and to add a relevant section or appendix.

I guess I'm hoping to shift our mental models a bit further from absolute or binary terms and closer to relative or tiered ones.  Each of the following could be a row or a column in a matrix, or just a set of questions asked of any other topic discussed at RWoT.  How might documenting the current thinking on all of the following be made simple enough to "trickle down" to the least-experienced developers and designers that will jump into the fray of these systems in the coming years?

### From authentication to "Levels of Assurance"

Authentication is never really binary-- an identity system is never *absolutely* certain of your identity, just certain enough for a given context. Banks, insurance companies, payment providers and governments often have highly coded (and explicitly **tiered**) standards for what level of identity verification or security corresponds to which government services, thresholds of insurance, etc.  The thresholds vary quite a bit between industries, use-cases, and, importantly, between jurisdictions.  Keeping track of such variation is crucial, and "solving" for one jurisdiction can limit reusability abroad.

In the EU case, eIDAS (which may be updated/iterated in 2020/2021 to deal directly with DLT and SSI technologies) sets up highly centralized mechanisms (like Certificate Authority whitelists) for pre-authorizing cross-border electronic signatures, authentications, and transactions between EU member states.  Complying with these requirements, while also rating highly on the "rubrics of decentralization" or censorship-resistance criteria, would be quite difficult in most cases.  For this reason, many developers of SSI solutions (particularly in Europe) could be tempted (or heavily incentivized) to build initially for the former, and retool later (if at all) for the latter.  Mapping out clearly what can and cannot be done under eIDAS in its present form, with examples drawn from the W3C VC Use Case documents, might be a useful overview of tradeoffs and pragmatic consequences of this or that authentication approach.

### From attestation to affidavit

In many cases, there needs to be shades of grey between institutional certainty and gossip or hearsay among end-users.  One form this could take is mentioned in Eric Welton's topic paper for this conference, which addresses "witnessing" or "confirming" rather than issuing credentials; another is Nader Helmy's paper from RWOT8 (Barcelona) on community-based or peer-issued credentials, which would require some kind of social graph or contextual reputation graph to give some relative weight versus purely self-attested/individual assertions.  Is there a place for affidavits and non-institutional letters of recommendation in our vocabulary?  Are there standardizable or portable non-institutional mechanisms for elevating affidavits above purely self-grounded pieces of information?

### From shared data access to shared liability

While self-sovereign, individual control of Encrypted Data Vaults or allotments of storage on identity hubs controlled by a single DID might *seem* intuitive enough, it might be good (particularly given the rush to get some amount of standardization and interoperable reference implementations built and approved) to check how EDV and other DID-storage options map to GDPR controller/processor distinctions, eIDAS identity levels of assurance, etc.  Furthermore, MPC- or other multi-sig storage could also be a can of worms worth checking, as could delegation or transferability of access to a DID-store.  Does opening up DID-storage to delegation or multi-sig break some compliance with legal and/or liability frameworks?

### From privacy-preserving to correlation-resisting

While cryptography offers a certain sense of certainty about anonymization or pseudonymization of accounts or activity, we might perhaps think in terms of relative obfuscation and assume that artificial intelligence will increasingly be deployed to "fingerprint" and/or correlate activity online, de-anonymizing or de-pseudonymizing traffic. Particularly when a developer or designer is unfamiliar with the web's dark underbelly of adtech, tracking, and "behavioral analysis," these kinds of considerations can be asking a lot.  Could Web2 "transports" and legacy bridges (both to existing web infrastructure and to centralized identity systems, including governmental ones) be seen as introducing additional risks or avoidable vectors of after-the-fact trackability that undo our work elsewhere in the system?  Is it worth documenting such a list as guidance to people building well-intended W3C-compliant systems?  Are there quick fixes, stitches-in-time, and best practices that mitigate these vectors?
